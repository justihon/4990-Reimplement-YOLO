{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68effe6a-b75d-4f66-9488-231b419a3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ultralytics opencv-python matplotlib\n",
    "\n",
    "# Headless/plot-safe setup for Windows/Jupyter (prevents kernel restarts)\n",
    "import os\n",
    "os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import torch, glob, os, shutil\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e06afb-2df3-4059-93ec-b866255e531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your dataset path\n",
    "DATA_ROOT = Path(r\"C:\\Users\\Owner\\datasets\\african-wildlife\")\n",
    "\n",
    "# Make/overwrite data.yaml (use forward slashes for YOLO)\n",
    "yaml_path = DATA_ROOT / \"data.yaml\"\n",
    "yaml_text = f\"\"\"# YOLO dataset config (African Wildlife)\n",
    "path: {DATA_ROOT.as_posix()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "names:\n",
    "  0: buffalo\n",
    "  1: elephant\n",
    "  2: rhino\n",
    "  3: zebra\n",
    "\"\"\"\n",
    "yaml_path.write_text(yaml_text)\n",
    "print(\"Wrote:\", yaml_path)\n",
    "print(yaml_path.read_text())\n",
    "\n",
    "# Quick structure sanity check\n",
    "img_exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\"}\n",
    "def cnt_imgs(p): return sum(1 for x in (p).rglob(\"*\") if x.suffix.lower() in img_exts)\n",
    "def cnt_txt(p):  return sum(1 for x in (p).rglob(\"*.txt\"))\n",
    "print(\"train images:\", cnt_imgs(DATA_ROOT/\"images\"/\"train\"),\n",
    "      \"| train labels:\", cnt_txt(DATA_ROOT/\"labels\"/\"train\"))\n",
    "print(\"val   images:\", cnt_imgs(DATA_ROOT/\"images\"/\"val\"),\n",
    "      \"| val   labels:\", cnt_txt(DATA_ROOT/\"labels\"/\"val\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecefd413-10a3-48f1-bbc5-f3ed4ab6d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training properly (safe settings)\n",
    "model = YOLO(\"yolov8n.pt\")  # you can also start from previous best.pt if you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79330de1-5526-4d25-9124-955ec4296b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data=str(yaml_path),\n",
    "    epochs=10,\n",
    "    imgsz=512,\n",
    "    batch=8,\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "    workers=0,\n",
    "    cache=False,\n",
    "    plots=False,           # keep False to avoid kernel restart\n",
    "    project=\"runs\",\n",
    "    name=\"african\",\n",
    "    exist_ok=True,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    patience=20\n",
    ")\n",
    "\n",
    "model.names\n",
    "\n",
    "print(\"Saved weights:\", glob.glob(\"runs/detect/african/weights/*.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489c086-d77b-4c83-88b6-e183ea9233f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os, glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Robustly pick a weight file (prefer best.pt)\n",
    "candidates = [\n",
    "    r\"runs/african/weights/best.pt\",\n",
    "    r\"runs/african/weights/last.pt\",\n",
    "    r\"runs/detect/african/weights/best.pt\",\n",
    "    r\"runs/detect/african/weights/last.pt\",\n",
    "]\n",
    "weight = next((p for p in candidates if os.path.exists(p)), None)\n",
    "print(\"Using weights:\", weight)\n",
    "\n",
    "model = YOLO(weight)\n",
    "\n",
    "# Evaluate\n",
    "metrics = model.val()\n",
    "print(metrics)\n",
    "\n",
    "# Predict on validation images and save visualizations\n",
    "DATA_ROOT = Path(r\"C:\\Users\\Owner\\datasets\\african-wildlife\")\n",
    "preds = model.predict(source=str(DATA_ROOT / \"images\" / \"val\"), imgsz=512, save=True)\n",
    "save_dir = preds[0].save_dir if preds else \"runs/detect/predict\"\n",
    "print(\"Predictions saved to:\", save_dir)\n",
    "\n",
    "# Show a couple of predicted images in the notebook\n",
    "pred_images = glob.glob(os.path.join(save_dir, \"*.jpg\"))\n",
    "for p in pred_images[:2]:\n",
    "    display(Image(filename=p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b184fe-64d9-4491-b4f4-6738844643e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "model = YOLO(\"runs/african/weights/best.pt\")\n",
    "\n",
    "# Run prediction on a single image\n",
    "img_path = r\"C:\\Users\\Owner\\datasets\\african-wildlife\\images\\test\"\n",
    "results = model.predict(source=img_path, save=True, imgsz=512)\n",
    "results[0].show()  # Opens image with detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66e5b4-84fc-409a-8a37-89c173bb5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c3d89-44a7-4748-a900-333bea005fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "# -----------------------------------\n",
    "# 1) Load trained YOLO model\n",
    "# -----------------------------------\n",
    "weights = \"runs/african/weights/best.pt\"   # <-- update path if needed\n",
    "model = YOLO(weights)\n",
    "\n",
    "# -----------------------------------\n",
    "# 2) Load validation images + labels\n",
    "# -----------------------------------\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lehin\\Downloads\\african-wildlife\")\n",
    "img_dir = DATA_ROOT / \"images\" / \"val\"\n",
    "label_dir = DATA_ROOT / \"labels\" / \"val\"\n",
    "\n",
    "# Collect image paths\n",
    "img_paths = []\n",
    "for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "    img_paths.extend(img_dir.glob(ext))\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# -----------------------------------\n",
    "# 3) Build ground truth + YOLO predictions\n",
    "# -----------------------------------\n",
    "for img_path in img_paths:\n",
    "\n",
    "    # --- Load ground-truth label file ---\n",
    "    label_path = label_dir / (img_path.stem + \".txt\")\n",
    "    if not label_path.exists():\n",
    "        continue\n",
    "\n",
    "    # Read true labels\n",
    "    with open(label_path, \"r\") as f:\n",
    "        labels = f.read().strip().splitlines()\n",
    "        for line in labels:\n",
    "            true_class = int(line.split()[0])\n",
    "            y_true.append(true_class)\n",
    "\n",
    "    # --- Predict using YOLO ---\n",
    "    results = model(img_path, imgsz=512, conf=0.25, verbose=False)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    if boxes is None:\n",
    "        continue\n",
    "\n",
    "    # Read predicted labels\n",
    "    for b in boxes:\n",
    "        pred_class = int(b.cls)\n",
    "        y_pred.append(pred_class)\n",
    "\n",
    "# -----------------------------------\n",
    "# 4) Compute Confusion Matrix\n",
    "# -----------------------------------\n",
    "class_names = [\"Buffalo\", \"Elephant\", \"Rhino\", \"Zebra\"]  # <-- update if different\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
    "\n",
    "# -----------------------------------\n",
    "# 5) Plot and SAVE confusion matrix\n",
    "# -----------------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar=True\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save instead of plt.show()\n",
    "output_path = \"confusion_matrix.png\"\n",
    "plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(f\"Confusion matrix saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc423dbb-b3c8-4b3e-9b22-821141143117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Paths & model\n",
    "# ---------------------------\n",
    "weights = \"runs/african/weights/best.pt\"   # <-- change if needed\n",
    "model = YOLO(weights)\n",
    "\n",
    "# use your TEST images here (or val if you prefer)\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lehin\\Downloads\\african-wildlife\")\n",
    "img_dir   = DATA_ROOT / \"images\" / \"val\"      # or \"test\"\n",
    "label_dir = DATA_ROOT / \"labels\" / \"val\"      # or \"test\"\n",
    "\n",
    "class_names = [\"Buffalo\", \"Elephant\", \"Rhino\", \"Zebra\"]  # update if needed\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Collect GT + predictions\n",
    "# ---------------------------\n",
    "img_paths = []\n",
    "for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "    img_paths.extend(img_dir.glob(ext))\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# cell_images[(true_class, pred_class)] = [img paths...]\n",
    "cell_images = {}\n",
    "\n",
    "for img_path in img_paths:\n",
    "    # ground-truth labels\n",
    "    label_path = label_dir / (img_path.stem + \".txt\")\n",
    "    if not label_path.exists():\n",
    "        continue\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "\n",
    "    # predict with YOLO\n",
    "    results = model(img_path, imgsz=512, conf=0.25, verbose=False)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    # if no detections, skip (or treat as background if you prefer)\n",
    "    if boxes is None or len(boxes) == 0:\n",
    "        continue\n",
    "\n",
    "    # For simplicity: pair each GT object with one predicted object of same index.\n",
    "\n",
    "    for idx, line in enumerate(lines):\n",
    "        true_cls = int(line.split()[0])\n",
    "        y_true.append(true_cls)\n",
    "\n",
    "        if idx < len(boxes):\n",
    "            pred_cls = int(boxes[idx].cls)\n",
    "        else:\n",
    "            # if fewer predictions than GT, treat as \"missed\" prediction\n",
    "            # here we just repeat true_cls so it lands on the diagonal;\n",
    "            # alternatively you can use a special \"background\" label.\n",
    "            pred_cls = true_cls\n",
    "\n",
    "        y_pred.append(pred_cls)\n",
    "\n",
    "        # track which images contributed to each cell\n",
    "        key = (true_cls, pred_cls)\n",
    "        cell_images.setdefault(key, []).append(str(img_path))\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Confusion matrix\n",
    "# ---------------------------\n",
    "labels_idx = list(range(len(class_names)))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_idx)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar=True\n",
    ")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix (YOLO on test images)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_png = \"confusion_matrix.png\"\n",
    "plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "print(\"Confusion matrix saved to:\", out_png)\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Show which images are in each cell\n",
    "# ---------------------------\n",
    "print(\"\\nExamples for each (True, Pred) cell:\")\n",
    "for (t, p), paths in cell_images.items():\n",
    "    print(f\"True={class_names[t]:8s}, Pred={class_names[p]:8s}  -> {len(paths)} image(s)\")\n",
    "    # print up to 3 example paths for this cell\n",
    "    for ex in paths[:3]:\n",
    "        print(\"   \", ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bad8d-ee1c-48a4-b5eb-c5cd68df17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"module://matplotlib_inline.backend_inline\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# -----------------------------------\n",
    "# 1) Load YOLO model\n",
    "# -----------------------------------\n",
    "weights = \"runs/african/weights/best.pt\"   # <-- change if needed\n",
    "model = YOLO(weights)\n",
    "\n",
    "# -----------------------------------\n",
    "# 2) Load test/validation images + labels\n",
    "# -----------------------------------\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lehin\\Downloads\\african-wildlife\")\n",
    "img_dir   = DATA_ROOT / \"images\" / \"val\"\n",
    "label_dir = DATA_ROOT / \"labels\" / \"val\"\n",
    "\n",
    "class_names = [\"Buffalo\", \"Elephant\", \"Rhino\", \"Zebra\"]  # update if needed \n",
    "# Collect image paths\n",
    "img_paths = []\n",
    "for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "    img_paths.extend(img_dir.glob(ext))\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# -----------------------------------\n",
    "# 3) Evaluate all images\n",
    "# -----------------------------------\n",
    "for img_path in img_paths:\n",
    "    \n",
    "    # Load ground truth\n",
    "    label_path = label_dir / (img_path.stem + \".txt\")\n",
    "    if not label_path.exists():\n",
    "        continue\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        labels = f.read().strip().splitlines()\n",
    "\n",
    "    # Predict with YOLO\n",
    "    results = model(img_path, imgsz=512, conf=0.25, verbose=False)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    if boxes is None or len(boxes) == 0:\n",
    "        continue\n",
    "\n",
    "    # pair each GT with predicted classes\n",
    "    for idx, line in enumerate(labels):\n",
    "        true_cls = int(line.split()[0])\n",
    "        y_true.append(true_cls)\n",
    "\n",
    "        if idx < len(boxes):\n",
    "            pred_cls = int(boxes[idx].cls)\n",
    "        else:\n",
    "            pred_cls = true_cls  # fallback if missing predictions\n",
    "\n",
    "        y_pred.append(pred_cls)\n",
    "\n",
    "# -----------------------------------\n",
    "# 4) Build confusion matrix\n",
    "# -----------------------------------\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
    "\n",
    "# -----------------------------------\n",
    "# 5) Plot confusion matrix (DISPLAY in Notebook)\n",
    "# -----------------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar=True\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix (YOLO Model)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd15029-cc91-4361-a88d-9b131e453205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure plots show inside the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use(\"module://matplotlib_inline.backend_inline\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Paths: weights + data.yaml\n",
    "# -------------------------------\n",
    "weights = r\"runs\\african\\weights\\best.pt\"     # <- change to your best.pt if needed\n",
    "DATA_ROOT = Path(r\"C:\\Users\\Owner\\datasets\\african-wildlife\")\n",
    "yaml_path = DATA_ROOT / \"data.yaml\"           # the one we created earlier\n",
    "\n",
    "assert Path(weights).exists(), f\"Weights not found: {weights}\"\n",
    "assert yaml_path.exists(), f\"data.yaml not found: {yaml_path}\"\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Load model and run VAL\n",
    "#    This will run on ALL images in the val split\n",
    "#    and create a confusion_matrix.png for you\n",
    "# -------------------------------\n",
    "model = YOLO(weights)\n",
    "\n",
    "results = model.val(\n",
    "    data=str(yaml_path),\n",
    "    split=\"val\",     # use the 'val' images from data.yaml\n",
    "    imgsz=512,\n",
    "    conf=0.25,\n",
    "    iou=0.7,\n",
    "    plots=True,      # <-- important: tells YOLO to save confusion matrix & curves\n",
    "    workers=0\n",
    ")\n",
    "\n",
    "print(\"Validation results saved in:\", results.save_dir)\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Find and display confusion_matrix.png\n",
    "# -------------------------------\n",
    "cm_candidates = list(Path(results.save_dir).glob(\"confusion_matrix*.png\"))\n",
    "if not cm_candidates:\n",
    "    raise FileNotFoundError(\"confusion_matrix.png not found in results folder.\")\n",
    "\n",
    "cm_path = cm_candidates[0]\n",
    "print(\"Using confusion matrix:\", cm_path)\n",
    "\n",
    "img = Image.open(cm_path)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Confusion Matrix (YOLO, all val images)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b2cff-c90b-4c4f-bf0e-f3328dfd184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure plots display inside Jupyter\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use(\"module://matplotlib_inline.backend_inline\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# -----------------------------------\n",
    "# 1) Load model and dataset config\n",
    "# -----------------------------------\n",
    "weights = r\"runs/african/weights/best.pt\"     # <-- update if needed\n",
    "DATA_ROOT = Path(r\"C:\\Users\\Owner\\datasets\\african-wildlife\")\n",
    "yaml_path = DATA_ROOT / \"data.yaml\"\n",
    "\n",
    "assert Path(weights).exists(), f\"Weights not found: {weights}\"\n",
    "assert yaml_path.exists(), f\"data.yaml not found: {yaml_path}\"\n",
    "\n",
    "model = YOLO(weights)\n",
    "\n",
    "# -----------------------------------\n",
    "# 2) Run validation on ALL images in val split\n",
    "#    YOLO will auto-create confusion_matrix.png\n",
    "# -----------------------------------\n",
    "results = model.val(\n",
    "    data=str(yaml_path),\n",
    "    split=\"val\",\n",
    "    imgsz=512,\n",
    "    conf=0.25,\n",
    "    iou=0.7,\n",
    "    plots=True,      # <-- MUST BE TRUE to create confusion matrix\n",
    "    workers=0\n",
    ")\n",
    "\n",
    "print(\"Validation folder:\", results.save_dir)\n",
    "\n",
    "# -----------------------------------\n",
    "# 3) Find YOLO-generated confusion_matrix.png\n",
    "# -----------------------------------\n",
    "cm_candidates = list(Path(results.save_dir).glob(\"confusion_matrix*.png\"))\n",
    "if len(cm_candidates) == 0:\n",
    "    raise FileNotFoundError(\"No confusion_matrix.png created. Ensure plots=True during val().\")\n",
    "\n",
    "cm_path = cm_candidates[0]\n",
    "print(\"Confusion matrix file:\", cm_path)\n",
    "\n",
    "# -----------------------------------\n",
    "# 4) Display confusion matrix in notebook\n",
    "# -----------------------------------\n",
    "img = Image.open(cm_path)\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Confusion Matrix (YOLO - All Validation Images)\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------\n",
    "# 5) Image saved to path\n",
    "# -----------------------------------\n",
    "save_copy_path = DATA_ROOT / \"confusion_matrix_saved.png\"\n",
    "img.save(save_copy_path)\n",
    "print(\"Saved copy to:\", save_copy_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6f93b-9d92-416d-bc10-b1c79d115311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0801a66-1c4a-445f-ada9-d60a1878b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model will attempt to predict:\")\n",
    "\n",
    "for i in range(0, len(model.names)):\n",
    "    print(\"Class\", str(i) + \":\", model.names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c7206-b064-4aba-a829-6355ba898ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of video sources/cameras to check access\n",
    "sources = 5\n",
    "# Size of frame\n",
    "size = [800, 640]\n",
    "\n",
    "# Attempt to access first available camera, out of [sources] cameras\n",
    "for i in range(0, sources+1):\n",
    "    print(\"Attempting to connect to source {0}.\\n\".format(i))\n",
    "    camera = cv2.VideoCapture(i)\n",
    "    camera.set(3, size[0])\n",
    "    camera.set(4, size[1])\n",
    "    if camera.isOpened():\n",
    "        print(\"Connected to source {0}.\".format(i))\n",
    "        connected = True\n",
    "        break\n",
    "    else:\n",
    "        print(\"Cannot connect to source.\")\n",
    "        connected = False\n",
    "        if i < sources:\n",
    "            print(\"Changing source.\\n\\n\")\n",
    "        else:\n",
    "            print(\"No source available to connect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f768f26-fb17-4c9e-a0c2-a8343e0fc584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These values only need to be initialized once\n",
    "exitKey = 'q'\n",
    "frameName = \"Test Capture\"\n",
    "\n",
    "# Editable box design values\n",
    "boxColor = (255, 120, 175)\n",
    "boxThickness = 2\n",
    "\n",
    "# Editable text/frame values\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.75\n",
    "fontColor = (255, 255, 255)\n",
    "fontThickness = 2\n",
    "\n",
    "while connected:\n",
    "    capturing, frame = camera.read()\n",
    "    \n",
    "    if capturing:\n",
    "        # Run object detection on captured frame\n",
    "        results = model(frame, stream=True)\n",
    "\n",
    "        # Use detection results to draw boxes\n",
    "        for result in results:\n",
    "            item = result.boxes\n",
    "            \n",
    "            for box in item:\n",
    "                # Obtain Top-Left and Bottom-Right x/y values\n",
    "                xTL, yTL, xBR, yBR = box.xyxy[0]\n",
    "                # Convert to percent and truncate to hundredths place\n",
    "                confidence = math.floor((box.conf[0])*10000)/100\n",
    "                \n",
    "                cv2.rectangle(frame, (int(xTL), int(yTL)), (int(xBR), int(yBR)), boxColor, boxThickness)\n",
    "\n",
    "                classType = int(box.cls[0])\n",
    "                classAndConfidence = model.names[classType]\n",
    "\n",
    "                cv2.putText(frame, classAndConfidence, (int(xTL), int(yTL)), font, fontScale, fontColor, fontThickness)\n",
    "                # Statement below will print to output, but not to frame\n",
    "                print(model.names[classType], confidence)\n",
    "\n",
    "        # Display captured frame, including drawn boxes\n",
    "        cv2.imshow(frameName, frame)\n",
    "\n",
    "        # Will wait for key exitKey to be pressed\n",
    "        # Case-sensitive, 'Q' != 'q' and will require [Shift] to be pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(exitKey):\n",
    "            break\n",
    "            \n",
    "    # Break loop if capturing is interrupted\n",
    "    if not capturing:\n",
    "        print(\"Failed to capture.\")\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb484973-a4fb-4c14-94d3-3a51ce469d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of successful camera access, but error in drawing/displaying frame in previous cell preventing loop breaking\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
